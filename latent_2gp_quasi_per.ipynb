{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2185da9c-67f2-41f0-9599-6f2e8033a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "import pickle\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d075a1-e251-4309-85e4-387df73c892e",
   "metadata": {},
   "source": [
    "### Definition of the Quasi-Per kernel and its first + second derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceda0d97-be60-476d-9759-33220f03c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quasi_per(t1, t2, *, A=1.0, lnl=np.log(2.0), gamma=1.0, lnP=np.log(5.0)):\n",
    "    P = np.exp(lnP)\n",
    "    l = np.exp(lnl)\n",
    "    return A*np.exp(-gamma**2*np.sin(np.pi*(t1 - t2)/P)**2 - (t1 - t2)**2/(2*l**2))\n",
    "\n",
    "def quasi_per_cross(t1, t2, *, A=1.0, lnl=np.log(2.0), gamma=1.0, lnP=np.log(5.0)):\n",
    "    P = np.exp(lnP)\n",
    "    l = np.exp(lnl)\n",
    "    top = A*(P*t1 - P*t2 + np.pi*gamma**2*l**2*np.sin(2*np.pi*(t1 - t2)/P))\n",
    "    bot = (P*l**2)\n",
    "    return top*np.exp(-gamma**2*np.sin(np.pi*(t1 - t2)/P)**2 - t1**2/(2*l**2) + t1*t2/l**2 - t2**2/(2*l**2))/bot\n",
    "\n",
    "def quasi_per_grad(t1, t2, *, A=1.0, lnl=np.log(2.0), gamma=1.0, lnP=np.log(5.0)):\n",
    "    P = np.exp(lnP)\n",
    "    l = np.exp(lnl)\n",
    "    top = A*(P**2*l**2 - P**2*t1**2 + 2*P**2*t1*t2 - P**2*t2**2 - 2*np.pi*P*gamma**2*l**2*t1*np.sin(2*np.pi*(t1 - t2)/P) + 2*np.pi*P*gamma**2*l**2*t2*np.sin(2*np.pi*(t1 - t2)/P) - 4*np.pi**2*gamma**4*l**4*np.sin(np.pi*(t1 - t2)/P)**2*np.cos(np.pi*(t1 - t2)/P)**2 - 2*np.pi**2*gamma**2*l**4*np.sin(np.pi*(t1 - t2)/P)**2 + 2*np.pi**2*gamma**2*l**4*np.cos(np.pi*(t1 - t2)/P)**2)\n",
    "    bot = (P**2*l**4)\n",
    "    return top*np.exp(-gamma**2*np.sin(np.pi*(t1 - t2)/P)**2 - t1**2/(2*l**2) + t1*t2/l**2 - t2**2/(2*l**2))/bot\n",
    "\n",
    "def sample_gp(random, K, size=None):\n",
    "    return random.multivariate_normal(np.zeros(K.shape[0]), K, size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50915e10-f109-4062-ba45-42c8d16581f4",
   "metadata": {},
   "source": [
    "### Definition of the diagonal and off-diagonal terms for the covariance block matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63b33aa-dccf-4ed4-89c6-d987cd2f5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_11(t_1, t_2, p):\n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "        \n",
    "    A, B, C, D, lnl, gamma, lnP = p\n",
    "    \n",
    "    first_term = A**2 * quasi_per(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    # Note that the 2nd and 3rd terms cancel by a sign\n",
    "    fourth_term = B**2 * quasi_per_grad(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    \n",
    "    return first_term + fourth_term\n",
    "    \n",
    "def K_12(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnl, gamma, lnP = p\n",
    "    \n",
    "    first_term = A*C * quasi_per(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    second_term = A*D * quasi_per_cross(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    third_term = B*C * quasi_per_cross(t_2, t_1, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    fourth_term = B*D * quasi_per_grad(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "\n",
    "def K_21(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnl, gamma, lnP = p\n",
    "    \n",
    "    first_term = C*A * quasi_per(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    second_term = C*B * quasi_per_cross(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    third_term = D*A * quasi_per_cross(t_2, t_1, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    fourth_term = D*B * quasi_per_grad(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "    \n",
    "def K_22(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnl, gamma, lnP = p\n",
    "    \n",
    "    first_term = C**2 * quasi_per(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    # Note the 2nd and 3rd terms cancel by a sign\n",
    "    fourth_term = D**2 * quasi_per_grad(t_1, t_2, lnl=lnl, gamma=gamma, lnP=lnP)\n",
    "    \n",
    "    return first_term + fourth_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7277d1-3775-46b9-b21c-02b376c6c1f1",
   "metadata": {},
   "source": [
    "### Load in time series data, use only certain sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877e9280-b02d-4a4b-b568-0de6806961cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_path = \"example data/tau_0.050\"\n",
    "\n",
    "t_flux = np.load(var_path + \"_t.npy\")[500:2500]\n",
    "flux = np.load(var_path + \"_f.npy\")[500:2500]\n",
    "flux_err = np.load(var_path + \"_ferr.npy\")[500:2500]\n",
    "\n",
    "mu = np.mean(flux)\n",
    "flux = (flux / mu - 1) * 1e3\n",
    "flux_err = flux_err * 1e3 / mu\n",
    "\n",
    "t_rad_full = np.load(var_path + \"_t.npy\")[700:1750]\n",
    "rv_full = np.load(var_path + \"_rv.npy\")[700:1750]\n",
    "rv_err_full = np.load(var_path + \"_rverr.npy\")[700:1750]\n",
    "\n",
    "# Pull a random cadence of N~10,25,50\n",
    "rng_seed = 100 #404\n",
    "n_rv_cadence = 20\n",
    "\n",
    "random = np.random.default_rng(rng_seed)\n",
    "inds = np.sort(random.choice(np.arange(len(t_rad_full)), size=n_rv_cadence, replace=False))\n",
    "\n",
    "#inds = np.arange(0, len(t_rad_full), 225)\n",
    "\n",
    "t_rad = t_rad_full[inds]\n",
    "rv = rv_full[inds]\n",
    "rv_err = rv_err_full[inds]\n",
    "\n",
    "trained_data_dic = {\"Flux Time\":t_flux, \"Flux\":flux, \"Flux Error\":flux_err,\n",
    "                    \"RV Time\":t_rad_full, \"RV\":rv_full, \"RV Error\":rv_err,\n",
    "                    \"Sampled RV Time\":t_rad, \"Sampled RV\":rv, \"Sampled RV Error\":rv_err,\n",
    "                    \"RNG Seed\":rng_seed, \"N RV\":n_rv_cadence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc47dbf-dfca-433f-9641-6168be2384b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat(params, t_f, t_rv):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix\n",
    "    \"\"\"\n",
    "    Kappa11 = K_11(t_f, t_f, params)\n",
    "    Kappa12 = K_12(t_f, t_rv, params)\n",
    "    Kappa21 = Kappa12.T\n",
    "    Kappa22 = K_22(t_rv, t_rv, params)\n",
    "\n",
    "    cov = np.concatenate((\n",
    "          np.concatenate((Kappa11, Kappa12), axis=1),\n",
    "          np.concatenate((Kappa21, Kappa22), axis=1),\n",
    "          ), axis=0)\n",
    "    \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ced8cb-9304-4a63-bfcf-12a00de4f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like(r, K):\n",
    "    \"\"\"\n",
    "    Pulled from Dan's notebook, updated with Cholesky decomposition\n",
    "    https://github.com/dfm/gp/blob/main/solutions.ipynb\n",
    "    \n",
    "    The multivariate Gaussian ln-likelihood (up to a constant) for the\n",
    "    vector ``r`` given a covariance matrix ``K``.\n",
    "    \n",
    "    :param r: ``(N,)``   The residual vector with ``N`` points.\n",
    "    :param K: ``(N, N)`` The square (``N x N``) covariance matrix.\n",
    "    \n",
    "    :returns lnlike: ``float`` The Gaussian ln-likelihood. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Slow version, factor ~2x slower.\n",
    "    #return -0.5 * (np.dot(r, np.linalg.solve(K, r)) + np.linalg.slogdet(K)[1])\n",
    "\n",
    "    # Cholesky decomposition, faster\n",
    "    # For more info, check out: https://math.stackexchange.com/questions/3158303/using-cholesky-decomposition-to-compute-covariance-matrix-determinant\n",
    "    try:\n",
    "        cho_decomp = scipy.linalg.cho_factor(K)\n",
    "        log_det_cov = 2*np.sum(np.log(np.diag(cho_decomp[0])))\n",
    "        return -0.5 * (np.dot(r, scipy.linalg.cho_solve(cho_decomp, r)) + log_det_cov) #+ (len(r)*np.log(2.*np.pi)))\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a86f89-cff2-4bb9-8a2d-5afa9a1f0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_neg_log_prob(params, t_f, t_rv, y, y_err):\n",
    "    \n",
    "    #mean_flux, mean_rv = params[0], params[1] # do not implement mean for now\n",
    "    #mean = np.concatenate((np.zeros(len(t_f))+mean_flux, np.zeros(len(t_rv))+mean_rv))\n",
    "    jitter = np.exp(params[0])\n",
    "    kernel_params = params[1:]\n",
    "    \n",
    "    # Compute the covariance matrix for the first GP\n",
    "    K1 = cov_mat(kernel_params[:7], t_f, t_rv)\n",
    "    \n",
    "    # Compute the covariance matrix for the second GP\n",
    "    K2 = cov_mat(kernel_params[7:], t_f, t_rv)\n",
    "    \n",
    "    K = K1 + K2\n",
    "    K[np.diag_indices_from(K)] += y_err**2 + jitter\n",
    "    \n",
    "    # Compute the negative log likelihood\n",
    "    return -log_like(y, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd33873-7d7d-4330-887a-1b19b7e34ec1",
   "metadata": {},
   "source": [
    "### Optimize model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44957551-f097-4620-beb5-a80876f3847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gp_kernel(y):\n",
    "    \n",
    "    p0 = np.array([np.log(1.0**2.),\n",
    "                   0.5, -0.4, 0.7, 5.0,\n",
    "                   np.log(2.0), 1.0, np.log(5.0),\n",
    "                   0.5, -0.4, 0.7, 5.0,\n",
    "                   np.log(2.0), 1.0, np.log(5.0)])\n",
    "    \n",
    "    result = scipy.optimize.minimize(gp_neg_log_prob, p0, args=(t_flux, t_rad, y, np.concatenate((flux_err, rv_err))))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470e8225-c453-4847-bc81-9f1054f0c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -2552.434550611133\n",
      " hess_inv: array([[ 8.97615557e-04, -8.27132549e-05,  1.19105208e-04,\n",
      "         1.63157877e-02, -6.81418956e-02, -2.60011827e-04,\n",
      "        -2.69967789e-04, -2.33090945e-05, -6.75633176e-04,\n",
      "        -1.54685056e-04,  3.01961899e-02,  6.20010551e-02,\n",
      "         5.22495281e-04,  8.22030000e-04, -2.95903906e-04],\n",
      "       [-8.27132549e-05,  1.39894547e-05, -1.43396752e-05,\n",
      "        -2.36486192e-03,  6.67344207e-03,  2.30501251e-05,\n",
      "         2.08307683e-05,  3.12392089e-06,  6.93095574e-05,\n",
      "         8.16541196e-06, -2.35507766e-03, -5.92491147e-03,\n",
      "        -5.66333066e-05, -7.61925527e-05,  3.03403906e-05],\n",
      "       [ 1.19105208e-04, -1.43396752e-05,  2.56390537e-05,\n",
      "         2.26993615e-03, -8.97545996e-03, -3.89433916e-05,\n",
      "        -2.83777518e-05, -3.30826360e-06, -9.09966302e-05,\n",
      "        -1.73546333e-05,  4.02469767e-03,  8.48463184e-03,\n",
      "         6.69211250e-05,  1.07562458e-04, -4.15854267e-05],\n",
      "       [ 1.63157877e-02, -2.36486192e-03,  2.26993615e-03,\n",
      "         4.82873839e-01, -1.31317473e+00, -4.56929362e-03,\n",
      "        -4.49363970e-03, -6.30283450e-04, -1.36445913e-02,\n",
      "        -2.23849030e-03,  4.70778290e-01,  1.12520501e+00,\n",
      "         1.10582767e-02,  1.51790094e-02, -5.47291147e-03],\n",
      "       [-6.81418956e-02,  6.67344207e-03, -8.97545996e-03,\n",
      "        -1.31317473e+00,  5.32653116e+00,  1.91528614e-02,\n",
      "         2.09227599e-02,  1.56449658e-03,  5.34970533e-02,\n",
      "         1.28006563e-02, -2.34643632e+00, -4.80461411e+00,\n",
      "        -4.25565373e-02, -6.36227889e-02,  2.24655246e-02],\n",
      "       [-2.60011827e-04,  2.30501251e-05, -3.89433916e-05,\n",
      "        -4.56929362e-03,  1.91528614e-02,  8.09860848e-05,\n",
      "         7.28354702e-05,  7.32680600e-06,  1.89801832e-04,\n",
      "         4.32105509e-05, -8.64385965e-03, -1.76232946e-02,\n",
      "        -1.39848212e-04, -2.34213226e-04,  8.43292343e-05],\n",
      "       [-2.69967789e-04,  2.08307683e-05, -2.83777518e-05,\n",
      "        -4.49363970e-03,  2.09227599e-02,  7.28354702e-05,\n",
      "         9.78519825e-05,  9.49697434e-06,  2.03948235e-04,\n",
      "         4.72753444e-05, -9.56939945e-03, -1.88721901e-02,\n",
      "        -1.62916365e-04, -2.54798243e-04,  9.25010660e-05],\n",
      "       [-2.33090945e-05,  3.12392089e-06, -3.30826360e-06,\n",
      "        -6.30283450e-04,  1.56449658e-03,  7.32680600e-06,\n",
      "         9.49697434e-06,  3.87378441e-06,  1.36651905e-05,\n",
      "        -4.57883573e-06, -4.63774696e-04, -1.39103617e-03,\n",
      "        -8.79503471e-06, -2.00634362e-05,  1.10727151e-05],\n",
      "       [-6.75633176e-04,  6.93095574e-05, -9.09966302e-05,\n",
      "        -1.36445913e-02,  5.34970533e-02,  1.89801832e-04,\n",
      "         2.03948235e-04,  1.36651905e-05,  5.43761410e-04,\n",
      "         1.34050380e-04, -2.34111936e-02, -4.80211761e-02,\n",
      "        -4.36154475e-04, -6.36028267e-04,  2.20148155e-04],\n",
      "       [-1.54685056e-04,  8.16541196e-06, -1.73546333e-05,\n",
      "        -2.23849030e-03,  1.28006563e-02,  4.32105509e-05,\n",
      "         4.72753444e-05, -4.57883573e-06,  1.34050380e-04,\n",
      "         6.06736206e-05, -6.70919367e-03, -1.14486200e-02,\n",
      "        -1.10012520e-04, -1.53411536e-04,  3.83907502e-05],\n",
      "       [ 3.01961899e-02, -2.35507766e-03,  4.02469767e-03,\n",
      "         4.70778290e-01, -2.34643632e+00, -8.64385965e-03,\n",
      "        -9.56939945e-03, -4.63774696e-04, -2.34111936e-02,\n",
      "        -6.70919367e-03,  1.12467898e+00,  2.15161755e+00,\n",
      "         1.84076144e-02,  2.84201758e-02, -9.68455516e-03],\n",
      "       [ 6.20010551e-02, -5.92491147e-03,  8.48463184e-03,\n",
      "         1.12520501e+00, -4.80461411e+00, -1.76232946e-02,\n",
      "        -1.88721901e-02, -1.39103617e-03, -4.80211761e-02,\n",
      "        -1.14486200e-02,  2.15161755e+00,  4.37902085e+00,\n",
      "         3.78729213e-02,  5.76047746e-02, -2.06023520e-02],\n",
      "       [ 5.22495281e-04, -5.66333066e-05,  6.69211250e-05,\n",
      "         1.10582767e-02, -4.25565373e-02, -1.39848212e-04,\n",
      "        -1.62916365e-04, -8.79503471e-06, -4.36154475e-04,\n",
      "        -1.10012520e-04,  1.84076144e-02,  3.78729213e-02,\n",
      "         3.61175802e-04,  5.00888668e-04, -1.71799447e-04],\n",
      "       [ 8.22030000e-04, -7.61925527e-05,  1.07562458e-04,\n",
      "         1.51790094e-02, -6.36227889e-02, -2.34213226e-04,\n",
      "        -2.54798243e-04, -2.00634362e-05, -6.36028267e-04,\n",
      "        -1.53411536e-04,  2.84201758e-02,  5.76047746e-02,\n",
      "         5.00888668e-04,  7.65646237e-04, -2.70714461e-04],\n",
      "       [-2.95903906e-04,  3.03403906e-05, -4.15854267e-05,\n",
      "        -5.47291147e-03,  2.24655246e-02,  8.43292343e-05,\n",
      "         9.25010660e-05,  1.10727151e-05,  2.20148155e-04,\n",
      "         3.83907502e-05, -9.68455516e-03, -2.06023520e-02,\n",
      "        -1.71799447e-04, -2.70714461e-04,  1.06019029e-04]])\n",
      "      jac: array([-7.01904297e-04, -7.93457031e-04,  7.08007812e-03,  1.83105469e-04,\n",
      "        6.10351562e-05,  1.28173828e-03,  2.14233398e-02,  4.08935547e-03,\n",
      "        3.23486328e-03,  6.22558594e-03, -3.05175781e-05,  0.00000000e+00,\n",
      "        1.29699707e-02,  2.51464844e-02,  1.69372559e-02])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 8861\n",
      "      nit: 372\n",
      "     njev: 553\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([-1.04510679e+01, -1.99118641e+00, -4.17792152e-01, -3.20657998e+01,\n",
      "        6.48161293e+01,  5.83862071e-01,  8.45591315e-01,  3.21709652e+00,\n",
      "       -1.52166312e-01,  1.61603009e-02,  2.41985143e+01,  9.01890870e-02,\n",
      "       -6.07905426e-01, -1.79056670e+00,  4.54698596e+00])\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate((flux, rv))\n",
    "res = minimize_gp_kernel(y)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a9077f-eee4-4781-91e4-59c1b380a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat_test(params, t_test_f, t_test_rv, t_train_f, t_train_rv):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix for test data\n",
    "    \"\"\"\n",
    "    \n",
    "    Kappa11 = K_11(t_test_f, t_train_f, params)\n",
    "    Kappa12 = K_12(t_test_f, t_train_rv, params)\n",
    "    Kappa21 = K_21(t_test_rv, t_train_f, params)\n",
    "    Kappa22 = K_22(t_test_rv, t_train_rv, params)\n",
    "            \n",
    "    cov = np.concatenate((\n",
    "          np.concatenate((Kappa11, Kappa12), axis=1),\n",
    "          np.concatenate((Kappa21, Kappa22), axis=1),\n",
    "          ), axis=0)\n",
    "    \n",
    "    return cov\n",
    "\n",
    "def trained_cov(p):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix from optimized model parameters computed from training set \n",
    "    \"\"\"\n",
    "    cov_train1 = cov_mat(p[1:8], t_flux, t_rad)\n",
    "    cov_train2 = cov_mat(p[8:], t_flux, t_rad)\n",
    "    cov_train = cov_train1 + cov_train2\n",
    "\n",
    "    cov_train[np.diag_indices_from(cov_train)] += np.concatenate((flux_err, rv_err))**2 + np.exp(p[0])\n",
    "    \n",
    "    return cov_train\n",
    "\n",
    "def predict(p, n_test=1000):\n",
    "    \n",
    "    cov_train = trained_cov(p)\n",
    "    \n",
    "    factor = (scipy.linalg.cholesky(cov_train, overwrite_a=True, lower=False), False)\n",
    "    alpha  = scipy.linalg.cho_solve(factor, y, overwrite_b=True)\n",
    "    \n",
    "    t_test_flux = np.linspace(min(t_flux), max(t_flux), n_test)\n",
    "    t_test_rv  = np.linspace(min(t_rad_full), max(t_rad_full), n_test)\n",
    "    \n",
    "    #k_test_flux = np.zeros((len(t_test_flux)))\n",
    "    #k_test_rv = np.zeros((len(t_test_rv)))\n",
    "    \n",
    "    cov_test_only1 = cov_mat(p[1:8], t_test_flux, t_test_rv)\n",
    "    cov_test_only2 = cov_mat(p[8:],  t_test_flux, t_test_rv)\n",
    "    cov_test_only = cov_test_only1 + cov_test_only2\n",
    "    \n",
    "    cov_test1 = cov_mat_test(p[1:8], t_test_flux, t_test_rv, t_flux, t_rad) # t_flux and t_rad are training data\n",
    "    cov_test2 = cov_mat_test(p[8:],  t_test_flux, t_test_rv, t_flux, t_rad)\n",
    "    cov_test = cov_test1 + cov_test2\n",
    "    \n",
    "    mu = np.dot(cov_test, alpha)\n",
    "    var = cov_test_only[np.diag_indices_from(cov_test_only)]\n",
    "    inv_cov_test = np.linalg.solve(cov_train, cov_test.T)\n",
    "    var -= np.sum(cov_test.T * inv_cov_test, axis = 0)\n",
    "    \n",
    "    return mu, var, t_test_flux, t_test_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70115168-3382-4518-969e-ae30da0919ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var, t_test_flux, t_test_rv = predict(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19bf1d8-71a1-469b-a2fd-53d8ca5c53e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.04906386 -4.07631244 -4.09418314 ... -9.4443208  -8.06190656\n",
      " -6.66094229]\n"
     ]
    }
   ],
   "source": [
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6acc1cea-1dcd-4f00-962a-45be84924f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1852b20f0c45a58d6ff217d156a6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/slx5z51s7j9d_w8l_mb2blvc0001sl/T/ipykernel_13483/3504204243.py:44: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "def plot_data_and_model(p0=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, figsize=(12, 6), gridspec_kw={'hspace':0.4})\n",
    "    \n",
    "    ax[0].scatter(t_flux, flux, color='black', s=5.0, label='LC w/ errors')#, alpha=0.5)\n",
    "    ax[0].plot(t_flux, flux-flux_err, color='grey', label='True LC', zorder=9)#, alpha=0.5)\n",
    "    \n",
    "    rv_train = ax[1].scatter(t_rad, rv, color='orange', s=100.0, alpha=0.9, zorder=10, marker='*', label='Trained RVs')\n",
    "    rv_data = ax[1].scatter(t_rad_full, rv_full, color='black', s=5.0, label='RVs w/ errors')#, alpha=0.3)\n",
    "    true_rv, = ax[1].plot(t_rad_full, rv_full-rv_err_full, color='grey', label='True RVs')#, alpha=0.3)\n",
    "    \n",
    "    ax[0].plot(t_test_flux, mu[:len(t_test_flux)], lw=2.0, color='C0', ls='-', label='GP$_\\mathrm{LC}$', zorder=10)\n",
    "    rv_gp, = ax[1].plot(t_test_rv, mu[len(t_test_flux):], lw=2.0, color='C0', ls='-', zorder=1, label='GP$_\\mathrm{RV}$')\n",
    "    \n",
    "    ax[0].fill_between(t_test_flux, y1=mu[:len(t_test_flux)]-np.sqrt(var[:len(t_test_flux)]),\n",
    "                       y2=mu[:len(t_test_flux)]+np.sqrt(var[:len(t_test_flux)]), color='C0', alpha=0.5)\n",
    "    \n",
    "    ax[1].fill_between(t_test_rv, y1=mu[len(t_test_flux):]-np.sqrt(var[len(t_test_flux):]),\n",
    "                       y2=mu[len(t_test_flux):]+np.sqrt(var[len(t_test_flux):]), color='C0', alpha=0.25)\n",
    "    \n",
    "    ax[0].set_ylabel(r\"Norm. Flux (ppt)\")\n",
    "    ax[1].set_ylabel(r\"RV (m s$^{-1}$)\")\n",
    "    \n",
    "    ax[0].set_xlabel(r\"Time (day)\")\n",
    "    ax[1].set_xlabel(r\"Time (day)\")\n",
    "    \n",
    "    ax[0].set_xlim([min(t_flux), max(t_flux)])\n",
    "    ax[1].set_xlim([min(t_rad), max(t_rad)])\n",
    "    \n",
    "    ax[0].set_ylim([min(flux)-2.0, max(flux)+2.5])\n",
    "    ax[1].set_ylim([min(rv_full)-175., max(rv_full)+150.])\n",
    "    \n",
    "    ax[0].legend(fontsize=12, markerscale=2.0)\n",
    "    rv_l1 = ax[1].legend([rv_train, rv_data], [\"Trained RVs\", \"RVs w/ errors\"], fontsize=12, markerscale=1.5, loc='lower right')\n",
    "    rv_l2 = ax[1].legend([rv_gp, true_rv], [\"GP$_\\mathrm{RV}$\", \"True RV\"], fontsize=12, markerscale=1.5, loc='lower left')\n",
    "    ax[1].add_artist(rv_l1)\n",
    "\n",
    "    data_dict_fn = \"Two Latent GPs Tests/SqExp/\"\n",
    "    plot_fn = data_dict_fn + 'f500-2500_rv700-1750_nrv{0}_seed{1}.png'.format(n_rv_cadence, rng_seed)\n",
    "    #plot_fn = data_dict_fn + 'f0-1000_rv2500-3500_nrv7_equal_spaced.png'\n",
    "    #plt.savefig(plot_fn, bbox_inches='tight', dpi=400)\n",
    "    #plt.savefig(\"Plots/two_latent_GP_model_comp_nRV_10.png\", bbox_inches='tight', dpi=400)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#plot_data_and_model(p0 = np.array([0.1, 0.04, 0.07, 5.0, 20.0, 2.0]))\n",
    "plot_data_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7353e137-ab4d-4e1c-9cfe-0872c5f489d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd610a-b4e0-43fb-9e51-8a9607c31bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
