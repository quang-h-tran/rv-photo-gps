{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "db9c749e-c33d-4761-b407-c0e811d32c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6f1a3-1e3a-471f-89f8-91b7fd1b7886",
   "metadata": {},
   "source": [
    "### Definition of the Matern 5/2 Kernel and its derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d7a8208f-a697-4c1c-97a5-3c36ac371268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matern52(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return sigma ** 2 * (1 + x + x ** 2 / 3) * np.exp(-x)\n",
    "\n",
    "def matern52_cross(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return np.sqrt(5) * sigma ** 2 * np.sign(t1 - t2) * (x + x ** 2) / (3 * rho) * np.exp(-x)\n",
    "\n",
    "def matern52_grad(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return (5 / 3) * sigma ** 2 * (1 + x - x ** 2) / rho ** 2 * np.exp(-x)\n",
    "\n",
    "def sample_gp(random, K, size=None):\n",
    "    return random.multivariate_normal(np.zeros(K.shape[0]), K, size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86389378-e8a3-42f8-b0a0-e3263f15fedc",
   "metadata": {},
   "source": [
    "### Definition of the diagonal and off-diagonal terms for the covariance block matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "85546166-45ff-480a-8822-c6c7062830b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_11(t_1, t_2, p):\n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "        \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    # Note that the 2nd and 3rd terms cancel by a sign\n",
    "    first_term = A**2 * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    #second_term = A*B * matern52_cross(t_f[:, None], t_f[None, :])\n",
    "    #third_term = -B*A * matern52_cross(t_f[:, None], t_f[None, :])\n",
    "    fourth_term = B**2 * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + fourth_term\n",
    "    \n",
    "def K_12(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = A*C * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    second_term = A*D * matern52_cross(t_1, t_2, lnrho=lnrho)\n",
    "    third_term = B*C * matern52_cross(t_2, t_1, lnrho=lnrho)\n",
    "    fourth_term = B*D * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "\n",
    "def K_21(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = C*A * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    second_term = C*B * matern52_cross(t_1, t_2, lnrho=lnrho)\n",
    "    third_term = D*A * matern52_cross(t_2, t_1, lnrho=lnrho)\n",
    "    fourth_term = D*B * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "    \n",
    "def K_22(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    # Note the 2nd and 3rd terms cancel by a sign\n",
    "    first_term = C**2 * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    #second_term = C*D * matern52_cross(t_rv[:, None], t_rv[None, :])\n",
    "    #third_term = -D*C * matern52_cross(t_rv[:, None], t_rv[None, :])\n",
    "    fourth_term = D**2 * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + fourth_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2557ab6d-f61e-496a-ae7f-b18e0f696b11",
   "metadata": {},
   "source": [
    "### Load in time series data, use only certain sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ecc59fc0-738e-422d-942d-4765e203f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_path = \"example data/tau_0.050\"\n",
    "\n",
    "t_flux = np.load(var_path + \"_t.npy\")[:750]\n",
    "flux = np.load(var_path + \"_f.npy\")[:750]\n",
    "flux_err = np.load(var_path + \"_ferr.npy\")[:750]\n",
    "\n",
    "mu = np.mean(flux)\n",
    "flux = (flux / mu - 1) * 1e3\n",
    "flux_err = flux_err * 1e3 / mu\n",
    "\n",
    "t_rad = np.load(var_path + \"_t.npy\")[450:1000]\n",
    "rv = np.load(var_path + \"_rv.npy\")[450:1000]\n",
    "rv_err = np.load(var_path + \"_rverr.npy\")[450:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2f2f8485-d409-4646-a24c-97723d4650e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat(params, t_f, t_rv):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix\n",
    "    \"\"\"\n",
    "    Kappa11 = K_11(t_f, t_f, params)\n",
    "    Kappa12 = K_12(t_f, t_rv, params)\n",
    "    Kappa21 = Kappa12.T\n",
    "    Kappa22 = K_22(t_rv, t_rv, params)\n",
    "\n",
    "    cov = np.concatenate((\n",
    "          np.concatenate((Kappa11, Kappa12), axis=1),\n",
    "          np.concatenate((Kappa21, Kappa22), axis=1),\n",
    "          ), axis=0)\n",
    "    \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ff45c98b-4028-483d-ae4f-9fc3f349e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like(r, K):\n",
    "    \"\"\"\n",
    "    Pulled from Dan's notebook, updated with Cholesky decomposition\n",
    "    https://github.com/dfm/gp/blob/main/solutions.ipynb\n",
    "    \n",
    "    The multivariate Gaussian ln-likelihood (up to a constant) for the\n",
    "    vector ``r`` given a covariance matrix ``K``.\n",
    "    \n",
    "    :param r: ``(N,)``   The residual vector with ``N`` points.\n",
    "    :param K: ``(N, N)`` The square (``N x N``) covariance matrix.\n",
    "    \n",
    "    :returns lnlike: ``float`` The Gaussian ln-likelihood. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Slow version, factor ~2x slower.\n",
    "    #return -0.5 * (np.dot(r, np.linalg.solve(K, r)) + np.linalg.slogdet(K)[1])\n",
    "\n",
    "    # Cholesky decomposition, faster\n",
    "    # For more info, check out: https://math.stackexchange.com/questions/3158303/using-cholesky-decomposition-to-compute-covariance-matrix-determinant\n",
    "    try:\n",
    "        cho_decomp = scipy.linalg.cho_factor(K)\n",
    "        log_det_cov = 2*np.sum(np.log(np.diag(cho_decomp[0])))\n",
    "        return -0.5 * (np.dot(r, scipy.linalg.cho_solve(cho_decomp, r)) + log_det_cov)# + (len(r)*np.log(2.*np.pi)))\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3546dcaa-580f-4e92-88d4-377e2e72fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_log_prob(params, t_f, t_rv, y, y_err):\n",
    "    \"\"\"\n",
    "    add in mean flux and mean RVs as potential parameters in the model\n",
    "    \n",
    "    Hard uniform bounds for coefficients\n",
    "    \"\"\"\n",
    "    \n",
    "    b = [(0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5)),\n",
    "         (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5))]\n",
    "    \n",
    "    for b, p in zip(bounds, params):\n",
    "        if p < b[0] or p > b[-1]:\n",
    "            return -np.inf\n",
    "    \n",
    "    # Compute the covariance matrix for the first GP\n",
    "    K1 = cov_mat(params[:5], t_f, t_rv)\n",
    "    \n",
    "    # Compute the covariance matrix for the second GP\n",
    "    K2 = cov_mat(params[5:], t_f, t_rv)\n",
    "    \n",
    "    K = K1 + K2\n",
    "    K[np.diag_indices_from(K)] += y_err**2\n",
    "    \n",
    "    # Compute the log likelihood\n",
    "    return log_like(y, K)\n",
    "\n",
    "def gp_neg_log_prob(params, t_f, t_rv, y, y_err):\n",
    "    \n",
    "    # Compute the covariance matrix for the first GP\n",
    "    K1 = cov_mat(params[:5], t_f, t_rv)\n",
    "    \n",
    "    # Compute the covariance matrix for the second GP\n",
    "    K2 = cov_mat(params[5:], t_f, t_rv)\n",
    "    \n",
    "    K = K1 + K2\n",
    "    K[np.diag_indices_from(K)] += y_err**2\n",
    "    \n",
    "    # Compute the negative log likelihood\n",
    "    return -log_like(y, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8a302-4250-4f75-8de2-19e905c39cd4",
   "metadata": {},
   "source": [
    "### Optimize model parameters and Sample Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a60175d5-fa56-4666-ad48-f84afa85997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gp_kernel(y):\n",
    "    \n",
    "    p0 = np.array([0.5, -0.4, 0.7, 5.0, np.log(2.3),\n",
    "                   0.5, -0.4, 0.7, 5.0, np.log(2.3)])\n",
    "    \n",
    "    b = [(0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5)),\n",
    "         (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5))]\n",
    "    \n",
    "    #options={'disp': None, 'maxls': 20, 'iprint': -1, 'gtol': 1e-08, 'eps': 1e-08, 'maxiter': 15000, 'ftol': 1e-09, 'maxcor': 10, 'maxfun': 20000}\n",
    "    options = {'maxiter':25000}\n",
    "    \n",
    "    result = scipy.optimize.minimize(gp_neg_log_prob, p0, args=(t_flux, t_rad, y, np.concatenate((flux_err, rv_err))), method='Nelder-Mead', bounds=b, options=options)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a8964c31-8358-4880-87e8-ef25d70a9767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " final_simplex: (array([[ 1.91953491e+00, -1.79801451e+00,  2.34642056e+00,\n",
      "         7.78593009e+01,  1.60943791e+00,  6.83074296e+00,\n",
      "        -2.33352641e-01,  7.13428565e+00, -2.49932386e+02,\n",
      "         1.54207894e+00],\n",
      "       [ 1.91953560e+00, -1.79801458e+00,  2.34642810e+00,\n",
      "         7.78592817e+01,  1.60943791e+00,  6.83074290e+00,\n",
      "        -2.33352679e-01,  7.13428063e+00, -2.49932386e+02,\n",
      "         1.54207895e+00],\n",
      "       [ 1.91953434e+00, -1.79801451e+00,  2.34642428e+00,\n",
      "         7.78593017e+01,  1.60943791e+00,  6.83074287e+00,\n",
      "        -2.33352806e-01,  7.13427705e+00, -2.49932386e+02,\n",
      "         1.54207893e+00],\n",
      "       [ 1.91953308e+00, -1.79801442e+00,  2.34641697e+00,\n",
      "         7.78593809e+01,  1.60943791e+00,  6.83074378e+00,\n",
      "        -2.33352967e-01,  7.13427915e+00, -2.49932386e+02,\n",
      "         1.54207897e+00],\n",
      "       [ 1.91953362e+00, -1.79801447e+00,  2.34642130e+00,\n",
      "         7.78593287e+01,  1.60943791e+00,  6.83074344e+00,\n",
      "        -2.33353003e-01,  7.13427692e+00, -2.49932386e+02,\n",
      "         1.54207896e+00],\n",
      "       [ 1.91953576e+00, -1.79801450e+00,  2.34643015e+00,\n",
      "         7.78592725e+01,  1.60943791e+00,  6.83074261e+00,\n",
      "        -2.33352506e-01,  7.13427841e+00, -2.49932386e+02,\n",
      "         1.54207893e+00],\n",
      "       [ 1.91953330e+00, -1.79801452e+00,  2.34641883e+00,\n",
      "         7.78593538e+01,  1.60943791e+00,  6.83074349e+00,\n",
      "        -2.33352990e-01,  7.13427792e+00, -2.49932386e+02,\n",
      "         1.54207895e+00],\n",
      "       [ 1.91953370e+00, -1.79801473e+00,  2.34642262e+00,\n",
      "         7.78592943e+01,  1.60943791e+00,  6.83074218e+00,\n",
      "        -2.33353072e-01,  7.13427368e+00, -2.49932386e+02,\n",
      "         1.54207893e+00],\n",
      "       [ 1.91953459e+00, -1.79801443e+00,  2.34643098e+00,\n",
      "         7.78593367e+01,  1.60943791e+00,  6.83074368e+00,\n",
      "        -2.33352992e-01,  7.13427237e+00, -2.49932386e+02,\n",
      "         1.54207895e+00],\n",
      "       [ 1.91953431e+00, -1.79801456e+00,  2.34642640e+00,\n",
      "         7.78593095e+01,  1.60943791e+00,  6.83074294e+00,\n",
      "        -2.33352732e-01,  7.13427356e+00, -2.49932386e+02,\n",
      "         1.54207895e+00],\n",
      "       [ 1.91953602e+00, -1.79801456e+00,  2.34642941e+00,\n",
      "         7.78592669e+01,  1.60943791e+00,  6.83074257e+00,\n",
      "        -2.33352773e-01,  7.13428224e+00, -2.49932386e+02,\n",
      "         1.54207893e+00]]), array([685.58851509, 685.5885151 , 685.5885151 , 685.5885151 ,\n",
      "       685.5885151 , 685.5885151 , 685.5885151 , 685.5885151 ,\n",
      "       685.5885151 , 685.5885151 , 685.5885151 ]))\n",
      "           fun: 685.588515093101\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 2371\n",
      "           nit: 1640\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([ 1.91953491e+00, -1.79801451e+00,  2.34642056e+00,  7.78593009e+01,\n",
      "        1.60943791e+00,  6.83074296e+00, -2.33352641e-01,  7.13428565e+00,\n",
      "       -2.49932386e+02,  1.54207894e+00])\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate((flux, rv))\n",
    "res = minimize_gp_kernel(y)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1693245e-d892-4b61-b3e2-8ebc0bccf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5)),\n",
    "         (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5))]\n",
    "\n",
    "ndim = 5*2\n",
    "nwalkers = 250\n",
    "pos = res.x\n",
    "\n",
    "pos_fixed = []\n",
    "\n",
    "for b, p in zip(bounds, pos):\n",
    "    if p < b[0] + 0.1:\n",
    "        pos_fixed.append(p + 0.5)\n",
    "    elif p > b[-1] - 0.1:\n",
    "        pos_fixed.append(p - 0.5)\n",
    "    else:\n",
    "        pos_fixed.append(p)\n",
    "\n",
    "pos = pos + 1e-3*np.random.randn(nwalkers, ndim)\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, gp_log_prob,\n",
    "                                args=(t_flux, t_rad, np.concatenate((flux, rv)), np.concatenate((flux_err, rv_err))))\n",
    "\n",
    "#sampler.run_mcmc(pos, 1000, progress=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "81ee4ca3-5cee-4e1f-ab05-14e62c57efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"A\", \"B\", \"C\", \"D\", r\"log$(\\rho_1)$\",\n",
    "     \"E\", \"F\", \"G\", \"H\", r\"log$(\\rho_2)$\"]\n",
    "\n",
    "#np.save(\"example data/two_latent_GP_actual_data_samples.npy\", sampler.flatchain)\n",
    "#np.save(\"example data/two_latent_GP_mcmc_samples_full_model_n7500_optimized.npy\", sampler.flatchain)\n",
    "\n",
    "#corner.corner(sampler.flatchain[-1000:], labels=l)\n",
    "\n",
    "#corner.corner(samples, labels=[\"A\", \"B\", \"C\", \"D\", r\"$\\sigma$\", r\"$\\rho$\"], truths=[1.0, -5.0, 0.9, 12.5, np.log(4.0), np.log(2.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0448e71f-df4a-4b99-b2a0-1be51fe9c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = np.load(\"example data/two_latent_GP_mcmc_samples_full_model_n7500_optimized.npy\")\n",
    "#corner.corner(samples[25000:], labels=l, truths=p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7d7d8-5028-4160-aaf5-b02123e4c875",
   "metadata": {},
   "source": [
    "### Plot model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "56c2b760-d16c-40b6-afc6-7385a3701710",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = res.x\n",
    "#print(res.x)\n",
    "#t_flux_hold = np.concatenate((t_flux, [max(t_flux) + 1]))\n",
    "\n",
    "cov_train1 = cov_mat(p0[:5], t_flux, t_rad)\n",
    "cov_train2 = cov_mat(p0[5:], t_flux, t_rad)\n",
    "cov_train = cov_train1 + cov_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bcbdedfc-a200-42d3-8781-c3c57c2239f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((flux, rv))\n",
    "t = np.concatenate((t_flux, t_rad))\n",
    "\n",
    "factor = (scipy.linalg.cholesky(cov_train, overwrite_a=True, lower=False), False)\n",
    "alpha  = scipy.linalg.cho_solve(factor, y, overwrite_b=True)\n",
    "\n",
    "t_test_flux = np.linspace(min(t_flux), max(t_flux), 1000)\n",
    "t_test_rv  = np.linspace(min(t_rad), max(t_rad), 500)\n",
    "\n",
    "k_test_flux = np.zeros((len(t_test_flux)))\n",
    "k_test_rv = np.zeros((len(t_test_rv)))\n",
    "\n",
    "for i in range(len(t_test_flux)):\n",
    "    \n",
    "    flux_cov1_f = K_11(t_test_flux[i], t_flux, p0[:5])\n",
    "    flux_cov1_g = K_11(t_test_flux[i], t_flux, p0[5:])\n",
    "    flux_cov2_f = K_12(t_test_flux[i], t_rad, p0[:5])\n",
    "    flux_cov2_g = K_12(t_test_flux[i], t_rad, p0[5:])\n",
    "    \n",
    "    flux_cov1 = flux_cov1_f + flux_cov1_g\n",
    "    flux_cov2 = flux_cov2_f + flux_cov2_g\n",
    "    \n",
    "    k_test_flux[i] = np.dot(np.concatenate((flux_cov1, flux_cov2)), alpha)\n",
    "    \n",
    "for j in range(len(t_test_rv)):\n",
    "    \n",
    "    rv_cov2_f = K_22(t_test_rv[j], t_rad, p0[:5])\n",
    "    rv_cov2_g = K_22(t_test_rv[j], t_rad, p0[5:])\n",
    "    \n",
    "    rv_cov1_f = K_21(t_test_rv[j], t_flux, p0[:5])\n",
    "    rv_cov1_g = K_21(t_test_rv[j], t_flux, p0[5:])\n",
    "    \n",
    "    rv_cov2 = rv_cov2_f + rv_cov2_g\n",
    "    rv_cov1 = rv_cov1_f + rv_cov1_g\n",
    "    \n",
    "    k_test_rv[j] = np.dot(np.concatenate((rv_cov1, rv_cov2)), alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "230bb5b9-d83a-428f-8fdb-378e7e47c2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc6f86665754159901d7d67cb26bf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/slx5z51s7j9d_w8l_mb2blvc0001sl/T/ipykernel_42997/2219638672.py:25: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "def plot_data_and_model(p0=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, figsize=(12, 6), gridspec_kw={'hspace':0.2})\n",
    "    \n",
    "    ax[0].scatter(t_flux, flux, color='blue', s=20.0, alpha=0.5)\n",
    "    ax[1].scatter(t_rad, rv, color='orange', s=20.0, alpha=0.5)\n",
    "    \n",
    "    ax[0].plot(t_test_flux, k_test_flux, lw=2.0, color='black', ls='-', zorder=1)\n",
    "    ax[1].plot(t_test_rv, k_test_rv, lw=2.0, color='black', ls='-', zorder=1)\n",
    "    #ax[1].plot(t_rad, y_samp[len(t_flux):], lw=2.0, color='orange', ls='--')\n",
    "    \n",
    "    #ax[0].plot(t_flux, mod_f, lw=2.0, color='black', ls='--')\n",
    "    #ax[1].plot(t_rad, mod_rv, lw=2.0, color='black', ls='--')\n",
    "    \n",
    "    ax[0].set_ylabel(r\"Norm. Flux (ppt)\")\n",
    "    ax[1].set_ylabel(r\"RV (m s$^{-1}$)\")\n",
    "    \n",
    "    ax[1].set_xlabel(r\"Time (day)\")\n",
    "    \n",
    "    ax[0].set_xlim([min(t_flux), max(t_flux)])\n",
    "    ax[1].set_xlim([min(t_rad), max(t_rad)])\n",
    "    \n",
    "    #plt.savefig(\"example data/two_latent_GP_model_comparison.png\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#plot_data_and_model(p0 = np.array([0.1, 0.04, 0.07, 5.0, 20.0, 2.0]))\n",
    "plot_data_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9861798-6e83-4509-a1f0-182161b6c635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
