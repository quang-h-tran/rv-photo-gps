{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c863a1e-7c41-4cd9-80b8-d2f3a8f003c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "import pickle\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2557ab6d-f61e-496a-ae7f-b18e0f696b11",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load in time series data, use only certain sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc59fc0-738e-422d-942d-4765e203f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_path = \"example data/tau_0.050\"\n",
    "\n",
    "t_flux = np.load(var_path + \"_t.npy\")[500:2500]\n",
    "flux = np.load(var_path + \"_f.npy\")[500:2500]\n",
    "flux_err = np.load(var_path + \"_ferr.npy\")[500:2500]\n",
    "\n",
    "mu = np.mean(flux)\n",
    "flux = (flux / mu - 1) * 1e3\n",
    "flux_err = flux_err * 1e3 / mu\n",
    "\n",
    "t_rad_full = np.load(var_path + \"_t.npy\")[700:1750]\n",
    "rv_full = np.load(var_path + \"_rv.npy\")[700:1750]\n",
    "rv_err_full = np.load(var_path + \"_rverr.npy\")[700:1750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45affbe0-fbe4-4fb0-a8f6-9c7ececf72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_data(save=True, data_dict_fn=None, data_dict=None):\n",
    "    data_dict_fn = \"Two Latent GPs Tests/\" + data_dict_fn\n",
    "    \n",
    "    if save:\n",
    "        with open(data_dict_fn, 'wb') as handle:\n",
    "            pickle.dump(data_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        with open(data_dict_fn, 'rb') as handle:\n",
    "            data_dict = pickle.load(handle)\n",
    "            \n",
    "        return data_dict\n",
    "    \n",
    "#time_series_data(save=False, data_dict_fn='f750-2000_rv800-1750_nrv{0}_seed{1}.pickle'.format(n_rv_cadence, rng_seed), data_dict=trained_data_dic)\n",
    "#time_series_data(data_dict_fn='f0-1000_rv500-2000_nrv7_equal_spaced.pickle'.format(), data_dict=trained_data_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e7ff25-5593-463c-b21d-cd629d624ef6",
   "metadata": {},
   "source": [
    "### Planet Signal Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f007f72c-89b7-456a-baa9-78bf8954f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newton_Raphson_factor(E0, M, e=0.0):\n",
    "    top = M - E0 + (e*np.sin(E0))\n",
    "    bot = 1. - (e * np.cos(E0))\n",
    "\n",
    "    return top/bot\n",
    "\n",
    "def Newton_Raphson(M, E0, e=0.0):\n",
    "    correct = Newton_Raphson_factor(E0, M, e)\n",
    "    return correct\n",
    "\n",
    "def inter_NR(M, E0, n, e=0.0):\n",
    "    E = E0\n",
    "    for i in range(n):\n",
    "        E_n = Newton_Raphson_factor(E, M, e)\n",
    "        E = E_n + E\n",
    "\n",
    "    return E\n",
    "\n",
    "def x(a, E, e=0.0):\n",
    "    return a * (np.cos(E) - e)\n",
    "\n",
    "def y(a, E, e=0.0):\n",
    "    return a * np.sqrt(1 - e**2.) * np.sin(E)\n",
    "\n",
    "def f(E, e=0.0):\n",
    "    tan_f_2 = np.sqrt((1 + e)/(1 - e)) * np.tan(E/2.)\n",
    "    f_2 = np.arctan(tan_f_2)\n",
    "    return f_2 * 2.\n",
    "\n",
    "def T(a):\n",
    "    return a**(3./2.)\n",
    "\n",
    "def M(t, T, tau):\n",
    "    return ((2.*np.pi) / T) * (t - tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae373ed-5966-405c-acb2-3bfb94e831b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.39347559534244 m / s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "What you need to define in order to inject the planet:\n",
    "\n",
    "1a) semi-major axis (AU) OR\n",
    "1b) orbital period (year)\n",
    "2) eccenticity - set to 0.0\n",
    "3) inclination (rad) - can be taken from the starry configuration\n",
    "4) m_star (solar mass) - set to 1.0, as in starry\n",
    "5a) m_planet (jupiter mass) OR\n",
    "5b) K semiamplitude (m/s)\n",
    "6) tau0 (year) - set to 0.0 by default\n",
    "7) argument of periapsis (rad) - set to 0 since eccentricity is set to 0.0\n",
    "\"\"\"\n",
    "\n",
    "G = const.G\n",
    "G = G.to(u.AU**3 / (u.Msun * u.yr**2))\n",
    "\n",
    "def period(a, m2, m1=1.0*u.Msun):\n",
    "    a *= u.AU\n",
    "    m2 *= u.Mjup\n",
    "\n",
    "    top = 4. * np.pi**2. * a**3.\n",
    "    bot = G * (m1 + m2)\n",
    "\n",
    "    return np.sqrt(top/bot).to(u.yr).value\n",
    "\n",
    "def semi_major_axis(P, m2, m1=1.0*u.Msun):\n",
    "    P *= u.year\n",
    "    m2 *= u.Mjup\n",
    "\n",
    "    top = P**2 * G * (m1 + m2)\n",
    "    bot = 4. * np.pi**2.\n",
    "\n",
    "    return ((top / bot)**(1/3)).to(u.AU).value\n",
    "\n",
    "def K(m2, i, m1=1.0*u.Msun, *, e=0.0, T=None, a=None):\n",
    "\n",
    "    m2 = (m2 * u.Mjup).to(u.Msun)\n",
    "\n",
    "    if T is None and a:\n",
    "        a_hold = (((m1)/(m1+m2))*a).value\n",
    "        T = period(a_hold, m2.value, m1=m1)\n",
    "    else:\n",
    "        a_hold = semi_major_axis(T, m2.value) * u.AU\n",
    "        a_hold = (((m1)/(m1+m2))*a_hold).value\n",
    "        T = period(a_hold, m2.value, m1=m1)\n",
    "\n",
    "    T *= u.yr\n",
    "\n",
    "    top = (2.*np.pi*G)**(1/3) * m2 * np.sin(i)\n",
    "    bot = T**(1/3) * np.sqrt(1. - e**2.) * m1**(2/3)\n",
    "    # AU / yr\n",
    "    return (top/bot).to(u.m / u.s)\n",
    "\n",
    "def V(semi_amp, true_anom, *, e=0.0, w=0.0, V0=0.):\n",
    "    return V0 + semi_amp*(np.cos(w + true_anom) + e*np.cos(w))\n",
    "\n",
    "def planet_model(t, period, semi_amp, tau):\n",
    "    # Mean anomaly\n",
    "    M0 = M(t, period, tau)\n",
    "    # Eccentric anomaly\n",
    "    E = inter_NR(M=M0, E0=1.0, n=20)\n",
    "    # True anomaly\n",
    "    true_anom = f(E)\n",
    "    \n",
    "    return V(semi_amp, true_anom) # m/s\n",
    "    \n",
    "# I want a HJ: P = 12.5 days, m = 1.5 MJup\n",
    "planet_period = (9.0 * u.day).to(u.year).value\n",
    "planet_mass = 1.5 # Jupiter units\n",
    "planet_t0 = (15.0 * u.day).to(u.year).value # year\n",
    "sys_inc = np.deg2rad(86.5) # deg\n",
    "\n",
    "K_planet = K(planet_mass, sys_inc, T=planet_period)\n",
    "print(K_planet)\n",
    "\n",
    "planet_V = planet_model((t_rad_full*u.day).to(u.yr).value, planet_period, K_planet.value, planet_t0)\n",
    "\n",
    "rv_full_activity_only = rv_full.copy()\n",
    "\n",
    "rv_full += planet_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58efdf26-d5b5-4ed6-b641-ff4443aca91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ddfcc4a5a745d8967f41908841b6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "ax.scatter(t_rad_full, rv_full, s=7.5, color='black')\n",
    "ax.plot(t_rad_full, planet_V, color='blue', lw=2.0)\n",
    "ax.scatter(t_rad_full, rv_full_activity_only, s=2.5, color='orange')\n",
    "\n",
    "ax.set_xlabel(r\"Time (day)\")\n",
    "ax.set_ylabel(r\"RV (m s$^{-1}$\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7980c94f-04e1-4041-b335-5de80ca3d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f169a041-922e-452c-b142-edba6b566a37",
   "metadata": {},
   "source": [
    "### Get specific data indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97ce658-c009-4b49-8b7c-43378fe38b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull a random cadence of N~10,25,50\n",
    "rng_seed = 1001 #404\n",
    "n_rv_cadence = 50\n",
    "\n",
    "random = np.random.default_rng(rng_seed)\n",
    "inds = np.sort(random.choice(np.arange(len(t_rad_full)), size=n_rv_cadence, replace=False))\n",
    "\n",
    "#inds = np.arange(0, len(t_rad_full), 225)\n",
    "\n",
    "t_rad = t_rad_full[inds]\n",
    "rv = rv_full[inds]\n",
    "rv_err = rv_err_full[inds]\n",
    "\n",
    "trained_data_dic = {\"Flux Time\":t_flux, \"Flux\":flux, \"Flux Error\":flux_err,\n",
    "                    \"RV Time\":t_rad_full, \"RV\":rv_full, \"RV Error\":rv_err,\n",
    "                    \"Sampled RV Time\":t_rad, \"Sampled RV\":rv, \"Sampled RV Error\":rv_err,\n",
    "                    \"RNG Seed\":rng_seed, \"N RV\":n_rv_cadence}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6f1a3-1e3a-471f-89f8-91b7fd1b7886",
   "metadata": {},
   "source": [
    "### Definition of the Matern 5/2 kernel and its first + second derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a8208f-a697-4c1c-97a5-3c36ac371268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matern52(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return sigma ** 2 * (1 + x + x ** 2 / 3) * np.exp(-x)\n",
    "\n",
    "def matern52_cross(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return np.sqrt(5) * sigma ** 2 * np.sign(t1 - t2) * (x + x ** 2) / (3 * rho) * np.exp(-x)\n",
    "\n",
    "def matern52_grad(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return (5 / 3) * sigma ** 2 * (1 + x - x ** 2) / rho ** 2 * np.exp(-x)\n",
    "\n",
    "def sample_gp(random, K, size=None):\n",
    "    return random.multivariate_normal(np.zeros(K.shape[0]), K, size=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86389378-e8a3-42f8-b0a0-e3263f15fedc",
   "metadata": {},
   "source": [
    "### Definition of the diagonal and off-diagonal terms for the covariance block matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85546166-45ff-480a-8822-c6c7062830b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_11(t_1, t_2, p):\n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "        \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = A**2 * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    # Note that the 2nd and 3rd terms cancel by a sign\n",
    "    fourth_term = B**2 * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + fourth_term\n",
    "    \n",
    "def K_12(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = A*C * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    second_term = A*D * matern52_cross(t_1, t_2, lnrho=lnrho)\n",
    "    third_term = B*C * matern52_cross(t_2, t_1, lnrho=lnrho)\n",
    "    fourth_term = B*D * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "\n",
    "def K_21(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = C*A * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    second_term = C*B * matern52_cross(t_1, t_2, lnrho=lnrho)\n",
    "    third_term = D*A * matern52_cross(t_2, t_1, lnrho=lnrho)\n",
    "    fourth_term = D*B * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "    \n",
    "def K_22(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = C**2 * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    # Note the 2nd and 3rd terms cancel by a sign\n",
    "    fourth_term = D**2 * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + fourth_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f2f8485-d409-4646-a24c-97723d4650e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat(params, t_f, t_rv):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix\n",
    "    \"\"\"\n",
    "    Kappa11 = K_11(t_f, t_f, params)\n",
    "    Kappa12 = K_12(t_f, t_rv, params)\n",
    "    Kappa21 = Kappa12.T\n",
    "    Kappa22 = K_22(t_rv, t_rv, params)\n",
    "\n",
    "    cov = np.concatenate((\n",
    "          np.concatenate((Kappa11, Kappa12), axis=1),\n",
    "          np.concatenate((Kappa21, Kappa22), axis=1),\n",
    "          ), axis=0)\n",
    "    \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff45c98b-4028-483d-ae4f-9fc3f349e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_log_like(r, K):\n",
    "    \"\"\"\n",
    "    Pulled from Dan's notebook, updated with Cholesky decomposition\n",
    "    https://github.com/dfm/gp/blob/main/solutions.ipynb\n",
    "    \n",
    "    The multivariate Gaussian ln-likelihood (up to a constant) for the\n",
    "    vector ``r`` given a covariance matrix ``K``.\n",
    "    \n",
    "    :param r: ``(N,)``   The residual vector with ``N`` points.\n",
    "    :param K: ``(N, N)`` The square (``N x N``) covariance matrix.\n",
    "    \n",
    "    :returns lnlike: ``float`` The Gaussian ln-likelihood. \n",
    "    \"\"\"\n",
    "    # Slow version, factor ~2x slower.\n",
    "    #return -0.5 * (np.dot(r, np.linalg.solve(K, r)) + np.linalg.slogdet(K)[1])\n",
    "\n",
    "    # Cholesky decomposition, faster\n",
    "    # For more info, check out: https://math.stackexchange.com/questions/3158303/using-cholesky-decomposition-to-compute-covariance-matrix-determinant\n",
    "    try:\n",
    "        cho_decomp = scipy.linalg.cho_factor(K)\n",
    "        log_det_cov = 2*np.sum(np.log(np.diag(cho_decomp[0])))\n",
    "        return -0.5 * (np.dot(r, scipy.linalg.cho_solve(cho_decomp, r)) + log_det_cov) #+ (len(r)*np.log(2.*np.pi)))\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3546dcaa-580f-4e92-88d4-377e2e72fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_neg_log_prob(params, t_f, t_rv, y, y_err):\n",
    "    \n",
    "    jitter = np.exp(params[0])\n",
    "    period = np.exp(params[1])\n",
    "    semi_amp = np.exp(params[2])\n",
    "    tau = params[3]\n",
    "    kernel_params = params[4:]\n",
    "    kernel_params[0] = np.exp(kernel_params[0])\n",
    "    \n",
    "    planet = planet_model((t_rv*u.day).to(u.year).value, (period*u.day).to(u.year).value, semi_amp, (tau*u.day).to(u.year).value)\n",
    "    \n",
    "    # y - mod (only RVs)\n",
    "    ymmod = y.copy()\n",
    "    ymmod[len(t_f):] -= planet\n",
    "    \n",
    "    # Compute the covariance matrix for the first GP\n",
    "    K1 = cov_mat(kernel_params[:5], t_f, t_rv)\n",
    "    \n",
    "    # Compute the covariance matrix for the second GP\n",
    "    K2 = cov_mat(kernel_params[5:], t_f, t_rv)\n",
    "    \n",
    "    K = K1 + K2\n",
    "    K[np.diag_indices_from(K)] += y_err**2 + jitter\n",
    "    \n",
    "    # Compute the negative log likelihood\n",
    "    return -gp_log_like(ymmod, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8a302-4250-4f75-8de2-19e905c39cd4",
   "metadata": {},
   "source": [
    "### Optimize model parameters and Sample Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a60175d5-fa56-4666-ad48-f84afa85997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gp_kernel(y):\n",
    "    \n",
    "    #opt_kernel_params = np.array([#-1.15102806e+01,\n",
    "    #                     2.00000000e+00, -1.29627264e-02, 1.90738599e+01, -5.51867547e+01, 9.19003160e-01,\n",
    "    #                     2.51783582e-02, 4.64294260e-03, 2.33719347e-01, 1.98977475e+01, 3.07601905e-01])\n",
    "    \n",
    "    p0 = np.array([np.log(0.9**2.), np.log(11.0), np.log(180.0), 16.0,\n",
    "                   np.log(0.5), -0.4, 0.7, 5.0, np.log(2.3),\n",
    "                   0.5, -0.4, 0.7, 5.0, np.log(2.3)])\n",
    "    \n",
    "    b = [(np.log(1e-3**2), np.log(1e2**2)), np.log((5.0, 50.0)), np.log((100.0, 250.0)), (0.0, 50.0),\n",
    "         np.log((1e-3, 300.0)), (-300.0, 300.0), (-300.0, 300.0), (-300.0, 300.0), np.log((0.1, 5)),\n",
    "         (-300.0, 300.0), (-300.0, 300.0), (-300.0, 300.0), (-300.0, 300.0), np.log((0.1, 5))]\n",
    "    \n",
    "    #options = {'maxiter':25000}\n",
    "    #result = scipy.optimize.minimize(gp_neg_log_prob, p0, args=(t_flux, t_rad, y, np.concatenate((flux_err, rv_err))), method='Nelder-Mead', options={'maxiter':25000}, bounds=b)\n",
    "    \n",
    "    result = scipy.optimize.minimize(gp_neg_log_prob, p0, args=(t_flux, t_rad, y, np.concatenate((flux_err, rv_err))), bounds=b)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8964c31-8358-4880-87e8-ef25d70a9767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -524.5152517580124\n",
      " hess_inv: <14x14 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 1.38556390e+01, -7.48228790e+00,  2.32602135e+00,  1.61294338e+00,\n",
      "       -1.90156471e+01,  1.29195098e+01,  3.89149737e-02, -3.74586464e-01,\n",
      "       -1.01593044e+03, -1.38851423e+01, -6.08841418e+00,  4.75938200e-01,\n",
      "       -8.19454076e-02, -1.03983082e+03])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 840\n",
      "      nit: 12\n",
      "     njev: 56\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ -13.81478774,    2.09083296,    4.60517019,    0.        ,\n",
      "         -6.85366392,  299.66650442,  299.81732688,  299.9670042 ,\n",
      "          1.60943791, -299.99923299,  299.66005957,  299.74900444,\n",
      "        299.80195556,    1.60943791])\n",
      "[ -13.81478774    2.09083296    4.60517019    0.           -6.85366392\n",
      "  299.66650442  299.81732688  299.9670042     1.60943791 -299.99923299\n",
      "  299.66005957  299.74900444  299.80195556    1.60943791]\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate((flux, rv))\n",
    "res = minimize_gp_kernel(y)\n",
    "\n",
    "print(res)\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c0dc11a-dcdd-47a2-b87f-add17b3a1bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.81478773977623\n",
      "[2.09083296 4.60517019 0.        ]\n",
      "[ -6.85366392 299.66650442 299.81732688 299.9670042 ]\n",
      "1.6094379124341003\n",
      "[-299.99923299  299.66005957  299.74900444  299.80195556]\n",
      "1.6094379124341003\n"
     ]
    }
   ],
   "source": [
    "print(res.x[0])\n",
    "print(res.x[1:4])\n",
    "print(res.x[4:8])\n",
    "print(res.x[8])\n",
    "print(res.x[9:13])\n",
    "print(res.x[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f964e-44c6-40f7-a822-1def5fd19a8a",
   "metadata": {},
   "source": [
    "### Sample after optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1693245e-d892-4b61-b3e2-8ebc0bccf79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbounds = [(np.log(1e-3**2), np.log(1e2**2)), (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5)),\\n         (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5))]\\n\\nndim = 5*2 + 1\\nnwalkers = 250\\npos = res.x\\n\\npos_fixed = []\\n\\nfor b, p in zip(bounds, pos):\\n    if p < b[0] + 0.1:\\n        pos_fixed.append(p + 0.5)\\n    elif p > b[-1] - 0.1:\\n        pos_fixed.append(p - 0.5)\\n    else:\\n        pos_fixed.append(p)\\n\\npos = pos + 1e-3*np.random.randn(nwalkers, ndim)\\nsampler = emcee.EnsembleSampler(nwalkers, ndim, gp_log_prob,\\n                                args=(t_flux, t_rad, np.concatenate((flux, rv)), np.concatenate((flux_err, rv_err))))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gp_log_prob(params, t_f, t_rv, y, y_err):\n",
    "    \"\"\"\n",
    "    add in mean flux and mean RVs as potential parameters in the model?\n",
    "    mean is weird?\n",
    "    \n",
    "    params should be array-like that looks like:\n",
    "    \n",
    "    [mean(flux), mean(rv), log(jitter), A, B, C, D, log(rho_1), E, F, G, H, log(rho_2)]\n",
    "    \n",
    "    Hard uniform bounds for coefficients\n",
    "    \"\"\"\n",
    "    \n",
    "    b = [(np.log(1e-3**2), np.log(1e2**2)), (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5)),\n",
    "         (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5))]\n",
    "    \n",
    "    for b, p in zip(bounds, params):\n",
    "        if p < b[0] or p > b[-1]:\n",
    "            return -np.inf\n",
    "    \n",
    "    jitter = np.exp(params[0])\n",
    "    kernel_params = params[1:]\n",
    "    \n",
    "    # Compute the covariance matrix for the first GP\n",
    "    K1 = cov_mat(kernel_params[:5], t_f, t_rv)\n",
    "    \n",
    "    # Compute the covariance matrix for the second GP\n",
    "    K2 = cov_mat(kernel_params[5:], t_f, t_rv)\n",
    "    \n",
    "    K = K1 + K2\n",
    "    K[np.diag_indices_from(K)] += y_err**2 + jitter\n",
    "    \n",
    "    # Compute the log likelihood\n",
    "    return gp_log_like(y, K)\n",
    "\n",
    "\"\"\"\n",
    "bounds = [(np.log(1e-3**2), np.log(1e2**2)), (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5)),\n",
    "         (0.01, 10.0), (-3.0, 3.0), (-250.0, 250.0), (-250.0, 250.0), np.log((0.1, 5))]\n",
    "\n",
    "ndim = 5*2 + 1\n",
    "nwalkers = 250\n",
    "pos = res.x\n",
    "\n",
    "pos_fixed = []\n",
    "\n",
    "for b, p in zip(bounds, pos):\n",
    "    if p < b[0] + 0.1:\n",
    "        pos_fixed.append(p + 0.5)\n",
    "    elif p > b[-1] - 0.1:\n",
    "        pos_fixed.append(p - 0.5)\n",
    "    else:\n",
    "        pos_fixed.append(p)\n",
    "\n",
    "pos = pos + 1e-3*np.random.randn(nwalkers, ndim)\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, gp_log_prob,\n",
    "                                args=(t_flux, t_rad, np.concatenate((flux, rv)), np.concatenate((flux_err, rv_err))))\n",
    "\"\"\"\n",
    "#sampler.run_mcmc(pos, 1000, progress=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ee4ca3-5cee-4e1f-ab05-14e62c57efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\"log(jitter)\", \"$P_b$\", \"$K_b$\", \"A\", \"B\", \"C\", \"D\", r\"log$(\\rho_1)$\",\n",
    "     \"E\", \"F\", \"G\", \"H\", r\"log$(\\rho_2)$\"]\n",
    "\n",
    "#np.save(\"example data/two_latent_GP_actual_data_samples.npy\", sampler.flatchain)\n",
    "#np.save(\"example data/two_latent_GP_mcmc_samples_full_model_n7500_optimized.npy\", sampler.flatchain)\n",
    "\n",
    "#corner.corner(sampler.flatchain[-1000:], labels=l)\n",
    "\n",
    "#corner.corner(samples, labels=[\"A\", \"B\", \"C\", \"D\", r\"$\\sigma$\", r\"$\\rho$\"], truths=[1.0, -5.0, 0.9, 12.5, np.log(4.0), np.log(2.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0448e71f-df4a-4b99-b2a0-1be51fe9c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples = np.load(\"example data/two_latent_GP_mcmc_samples_full_model_n7500_optimized.npy\")\n",
    "#corner.corner(samples[25000:], labels=l, truths=p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7d7d8-5028-4160-aaf5-b02123e4c875",
   "metadata": {},
   "source": [
    "### Plot model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ffd5ac7-4fa1-4222-8370-d058c9b08ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat_test(params, t_test_f, t_test_rv, t_train_f, t_train_rv):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix for test data\n",
    "    \"\"\"\n",
    "    \n",
    "    #params = params[3:]\n",
    "    \n",
    "    Kappa11 = K_11(t_test_f, t_train_f, params)\n",
    "    Kappa12 = K_12(t_test_f, t_train_rv, params)\n",
    "    Kappa21 = K_21(t_test_rv, t_train_f, params)\n",
    "    Kappa22 = K_22(t_test_rv, t_train_rv, params)\n",
    "            \n",
    "    cov = np.concatenate((\n",
    "          np.concatenate((Kappa11, Kappa12), axis=1),\n",
    "          np.concatenate((Kappa21, Kappa22), axis=1),\n",
    "          ), axis=0)\n",
    "    \n",
    "    return cov\n",
    "\n",
    "def trained_cov(p):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix from optimized model parameters computed from training set \n",
    "    \"\"\"\n",
    "    cov_train1 = cov_mat(p[1:6], t_flux, t_rad)\n",
    "    cov_train2 = cov_mat(p[6:], t_flux, t_rad)\n",
    "    cov_train = cov_train1 + cov_train2\n",
    "\n",
    "    cov_train[np.diag_indices_from(cov_train)] += np.concatenate((flux_err, rv_err))**2 + np.exp(p[0])\n",
    "    \n",
    "    return cov_train\n",
    "\n",
    "def predict(p, y, n_test=1000):\n",
    "    \n",
    "    p[0] = np.exp(p[0])\n",
    "    \n",
    "    cov_train = trained_cov(p)\n",
    "    \n",
    "    factor = (scipy.linalg.cholesky(cov_train, overwrite_a=True, lower=False), False)\n",
    "    alpha  = scipy.linalg.cho_solve(factor, y, overwrite_b=True)\n",
    "    \n",
    "    t_test_flux = np.linspace(min(t_flux), max(t_flux), n_test)\n",
    "    t_test_rv  = np.linspace(min(t_rad_full), max(t_rad_full), n_test)\n",
    "    \n",
    "    cov_test_only1 = cov_mat(p[1:6], t_test_flux, t_test_rv)\n",
    "    cov_test_only2 = cov_mat(p[6:],  t_test_flux, t_test_rv)\n",
    "    cov_test_only = cov_test_only1 + cov_test_only2\n",
    "    \n",
    "    cov_test1 = cov_mat_test(p[1:6], t_test_flux, t_test_rv, t_flux, t_rad) # t_flux and t_rad are training data\n",
    "    cov_test2 = cov_mat_test(p[6:],  t_test_flux, t_test_rv, t_flux, t_rad)\n",
    "    cov_test = cov_test1 + cov_test2\n",
    "    \n",
    "    mu = np.dot(cov_test, alpha)\n",
    "    var = cov_test_only[np.diag_indices_from(cov_test_only)]\n",
    "    inv_cov_test = np.linalg.solve(cov_train, cov_test.T)\n",
    "    var -= np.sum(cov_test.T * inv_cov_test, axis = 0)\n",
    "    \n",
    "    return mu, var, t_test_flux, t_test_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcbdedfc-a200-42d3-8781-c3c57c2239f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p0 = res.x\n",
    "#mu, var = predict(alpha, p0, cov_train, t_test_flux, t_test_rv, t_flux, t_rad)\n",
    "#mu, var, t_test_flux, t_test_rv = predict(res.x)\n",
    "\n",
    "#opt_kern_params = np.array([2.00000000e+00, -1.29627264e-02, 1.90738599e+01, -5.51867547e+01, 9.19003160e-01,\n",
    "#                            2.51783582e-02, 4.64294260e-03, 2.33719347e-01, 1.98977475e+01, 3.07601905e-01])\n",
    "\n",
    "recovered_planet = planet_model((t_rad*u.day).to(u.yr).value, (np.exp(res.x[1]) * u.day).to(u.year).value, np.exp(res.x[2]), (res.x[3]* u.day).to(u.year).value)\n",
    "opt_kern_params = [res.x[0]] + list(res.x[4:])\n",
    "\n",
    "ymmod = y.copy()\n",
    "ymmod[len(t_flux):] -= recovered_planet\n",
    "\n",
    "mu, var, t_test_flux, t_test_rv = predict(opt_kern_params, ymmod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "021d551c-6e22-408a-b45a-0cb0b0f76be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.86570305  -4.07715773  -4.14676243 ... -37.07092272 -38.18406479\n",
      " -39.27078402]\n"
     ]
    }
   ],
   "source": [
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "230bb5b9-d83a-428f-8fdb-378e7e47c2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a3d4cb4e5e44969cca11d87fb62c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_data_and_model():\n",
    "    \n",
    "    # We'll use two separate gridspecs to have different margins, hspace, etc\n",
    "    gs_top = plt.GridSpec(4, 1, top=0.95)\n",
    "    gs_base = plt.GridSpec(4, 1, hspace=0)\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Top (unshared) axes\n",
    "    lc_ax = fig.add_subplot(gs_top[0,:])\n",
    "    \n",
    "    # The four shared axes\n",
    "    rv_ax = fig.add_subplot(gs_base[1,:]) # Need to create the first one to share...\n",
    "    other_axes = [fig.add_subplot(gs_base[i,:], sharex=rv_ax, sharey=rv_ax) for i in range(2, 4)]\n",
    "    bottom_axes = [rv_ax] + other_axes\n",
    "    \n",
    "    # Hide shared x-tick labels\n",
    "    for ax in bottom_axes[:-1]:\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "    \n",
    "    #fig, ax = plt.subplots(nrows=3, figsize=(12, 10), gridspec_kw={'hspace':[0.4, 0.0]})\n",
    "    \n",
    "    lc_ax.scatter(t_flux, flux, color='black', s=5.0, label='LC w/ errors')#, alpha=0.5)\n",
    "    lc_ax.plot(t_flux, flux-flux_err, color='grey', label='True LC', zorder=9)#, alpha=0.5)\n",
    "    lc_ax.plot(t_test_flux, mu[:len(t_test_flux)], lw=2.0, color='C0', ls='-', label='GP$_\\mathrm{LC}$', zorder=10)\n",
    "    \n",
    "    lc_ax.fill_between(t_test_flux, y1=mu[:len(t_test_flux)]-np.sqrt(var[:len(t_test_flux)]),\n",
    "                   y2=mu[:len(t_test_flux)]+np.sqrt(var[:len(t_test_flux)]), color='C0', alpha=0.5)\n",
    "    \n",
    "    plan_mod = planet_model((t_test_rv*u.day).to(u.yr).value, (np.exp(res.x[1]) * u.day).to(u.year).value, np.exp(res.x[2]), (res.x[3]* u.day).to(u.year).value)\n",
    "    \n",
    "    rv_train = rv_ax.scatter(t_rad, rv, color='orange', s=100.0, alpha=0.9, zorder=10, marker='*', label='Trained RVs')\n",
    "    rv_data = rv_ax.scatter(t_rad_full, rv_full, color='black', s=5.0, label='RVs w/ errors')#, alpha=0.3)\n",
    "    true_rv, = rv_ax.plot(t_rad_full, rv_full-rv_err_full, color='grey', label='True RVs')#, alpha=0.3)\n",
    "    full_model, = rv_ax.plot(t_test_rv, mu[len(t_test_flux):]+plan_mod, color='pink', lw=2.0, label='Full Model')\n",
    "    rv_ax.fill_between(t_test_rv, y1=mu[len(t_test_flux):]-np.sqrt(var[len(t_test_flux):])+plan_mod,\n",
    "                       y2=mu[len(t_test_flux):]+np.sqrt(var[len(t_test_flux):])+plan_mod, color='pink', alpha=0.25)\n",
    "    \n",
    "    rv_gp, = bottom_axes[1].plot(t_test_rv, mu[len(t_test_flux):], lw=2.0, color='C0', ls='-', zorder=1, label='GP$_\\mathrm{RV}$')\n",
    "    act = bottom_axes[1].scatter(t_rad_full, rv_full_activity_only, color='grey', label='Activity Data', s=5.0)\n",
    "    bottom_axes[1].fill_between(t_test_rv, y1=mu[len(t_test_flux):]-np.sqrt(var[len(t_test_flux):]),\n",
    "                       y2=mu[len(t_test_flux):]+np.sqrt(var[len(t_test_flux):]), color='C0', alpha=0.25)      \n",
    "    \n",
    "    rec_plan, = bottom_axes[2].plot(t_test_rv, plan_mod, color='maroon', lw=4.0, alpha=0.25, label='Recovered Planet')\n",
    "    tru_plan, = bottom_axes[2].plot(t_rad_full, planet_V, color='grey', lw=2.5, label='True, Injected Planet')\n",
    "    \n",
    "    lc_ax.set_ylabel(r\"Light Curve (ppt)\", fontsize=19)\n",
    "    rv_ax.set_ylabel(r\"Total RV (m s$^{-1}$)\", fontsize=18)\n",
    "    other_axes[0].set_ylabel(r\"Activity (m s$^{-1}$)\", fontsize=18)\n",
    "    other_axes[1].set_ylabel(r\"Planet (m s$^{-1}$)\", fontsize=18)\n",
    "    \n",
    "    lc_ax.set_xlabel(r\"Time (day)\", fontsize=20)\n",
    "    other_axes[-1].set_xlabel(r\"Time (day)\", fontsize=20)\n",
    "    \n",
    "    lc_ax.set_xlim([min(t_flux), max(t_flux)])\n",
    "    other_axes[-1].set_xlim([min(t_rad), max(t_rad)])\n",
    "    \n",
    "    lc_ax.set_ylim([min(flux)-2.0, max(flux)+2.5])\n",
    "    other_axes[-1].set_ylim([min(rv_full)-175., max(rv_full)+150.])\n",
    "    \n",
    "    for ax in bottom_axes:\n",
    "        ax.margins(0.05)\n",
    "    \n",
    "    lc_ax.legend(fontsize=14, markerscale=2.0)\n",
    "    rv_p1 = rv_ax.legend([true_rv, full_model], [\"True RV\", \"Total Model\"],\n",
    "                         fontsize=14, markerscale=1.5, bbox_to_anchor=(0.115,0.96), loc=\"upper left\")\n",
    "    rv_l1 = rv_ax.legend([rv_train, rv_data], [\"Trained RVs\", \"RVs w/ errors\"], fontsize=14, markerscale=1.5,\n",
    "                         bbox_to_anchor=(0.525,0.475), loc=\"upper right\")\n",
    "    bottom_axes[1].legend([act, rv_gp], [\"Activity\", \"GP$_\\mathrm{RV}$\"], fontsize=14, markerscale=1.5)\n",
    "    bottom_axes[2].legend(fontsize=14, markerscale=1.5)\n",
    "    rv_ax.add_artist(rv_p1)\n",
    "\n",
    "    data_dict_fn = \"Two Latent GPs Tests/Matern-52/\"\n",
    "    plot_fn = data_dict_fn + 'f500-2500_rv700-1750_nrv{0}_seed{1}.png'.format(n_rv_cadence, rng_seed)\n",
    "    #plot_fn = data_dict_fn + 'f0-1000_rv2500-3500_nrv7_equal_spaced.png'\n",
    "    #plt.savefig(plot_fn, bbox_inches='tight', dpi=400)\n",
    "    #plt.savefig(\"Plots/two_latent_GP_model_comp_nRV_10.png\", bbox_inches='tight', dpi=400)\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_data_and_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9861798-6e83-4509-a1f0-182161b6c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213a50e-af94-47d6-8868-25d646932d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
