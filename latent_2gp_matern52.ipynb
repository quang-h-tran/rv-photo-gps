{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3b01b6-184f-4804-b770-21a9343c09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "import pickle\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab388dd-1ac9-4d6b-bb69-96f56216ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_path = \"example data/tau_0.050\"\n",
    "\n",
    "t_flux = np.load(var_path + \"_t.npy\")[500:2500]\n",
    "flux = np.load(var_path + \"_f.npy\")[500:2500]\n",
    "flux_err = np.load(var_path + \"_ferr.npy\")[500:2500]\n",
    "\n",
    "mu = np.mean(flux)\n",
    "flux = (flux / mu - 1) * 1e3\n",
    "flux_err = flux_err * 1e3 / mu\n",
    "\n",
    "t_rad_full = np.load(var_path + \"_t.npy\")[700:1750]\n",
    "rv_full = np.load(var_path + \"_rv.npy\")[700:1750]\n",
    "rv_err_full = np.load(var_path + \"_rverr.npy\")[700:1750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23252ba1-5b01-49bf-b22a-976360460b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull a random cadence of N~10,25,50\n",
    "rng_seed = 100 #404\n",
    "n_rv_cadence = 20\n",
    "\n",
    "random = np.random.default_rng(rng_seed)\n",
    "inds = np.sort(random.choice(np.arange(len(t_rad_full)), size=n_rv_cadence, replace=False))\n",
    "\n",
    "#inds = np.arange(0, len(t_rad_full), 225)\n",
    "\n",
    "t_rad = t_rad_full[inds]\n",
    "rv = rv_full[inds]\n",
    "rv_err = rv_err_full[inds]\n",
    "\n",
    "trained_data_dic = {\"Flux Time\":t_flux, \"Flux\":flux, \"Flux Error\":flux_err,\n",
    "                    \"RV Time\":t_rad_full, \"RV\":rv_full, \"RV Error\":rv_err,\n",
    "                    \"Sampled RV Time\":t_rad, \"Sampled RV\":rv, \"Sampled RV Error\":rv_err,\n",
    "                    \"RNG Seed\":rng_seed, \"N RV\":n_rv_cadence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc72cdef-faa2-462d-a5c3-6d696aab722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matern52(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return sigma ** 2 * (1 + x + x ** 2 / 3) * np.exp(-x)\n",
    "\n",
    "def matern52_cross(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return np.sqrt(5) * sigma ** 2 * np.sign(t1 - t2) * (x + x ** 2) / (3 * rho) * np.exp(-x)\n",
    "\n",
    "def matern52_grad(t1, t2, *, lnsigma = np.log(1.0), lnrho = np.log(3.0)):\n",
    "    rho = np.exp(lnrho)\n",
    "    sigma = np.exp(lnsigma)\n",
    "    x = np.sqrt(5) * np.abs(t1 - t2) / rho\n",
    "    return (5 / 3) * sigma ** 2 * (1 + x - x ** 2) / rho ** 2 * np.exp(-x)\n",
    "\n",
    "def sample_gp(random, K, size=None):\n",
    "    return random.multivariate_normal(np.zeros(K.shape[0]), K, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44143b9f-b4ec-4d43-a1ae-fa58a4180808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_11(t_1, t_2, p):\n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "        \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = A**2 * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    # Note that the 2nd and 3rd terms cancel by a sign\n",
    "    fourth_term = B**2 * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + fourth_term\n",
    "    \n",
    "def K_12(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = A*C * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    second_term = A*D * matern52_cross(t_1, t_2, lnrho=lnrho)\n",
    "    third_term = B*C * matern52_cross(t_2, t_1, lnrho=lnrho)\n",
    "    fourth_term = B*D * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "\n",
    "def K_21(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = C*A * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    second_term = C*B * matern52_cross(t_1, t_2, lnrho=lnrho)\n",
    "    third_term = D*A * matern52_cross(t_2, t_1, lnrho=lnrho)\n",
    "    fourth_term = D*B * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + second_term + third_term + fourth_term\n",
    "    \n",
    "def K_22(t_1, t_2, p):\n",
    "    \n",
    "    if isinstance(t_1, np.ndarray) and isinstance(t_2, np.ndarray):\n",
    "        t_1 = t_1[:, None]\n",
    "        t_2 = t_2[None, :]\n",
    "    \n",
    "    A, B, C, D, lnrho = p\n",
    "    \n",
    "    first_term = C**2 * matern52(t_1, t_2, lnrho=lnrho)\n",
    "    # Note the 2nd and 3rd terms cancel by a sign\n",
    "    fourth_term = D**2 * matern52_grad(t_1, t_2, lnrho=lnrho)\n",
    "    \n",
    "    return first_term + fourth_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb28c7d-9ef3-46c1-ad7f-5051f6cd94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat(params, t_f, t_rv):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix\n",
    "    \"\"\"\n",
    "    Kappa11 = K_11(t_f, t_f, params)\n",
    "    Kappa12 = K_12(t_f, t_rv, params)\n",
    "    Kappa21 = Kappa12.T\n",
    "    Kappa22 = K_22(t_rv, t_rv, params)\n",
    "\n",
    "    cov = np.concatenate((\n",
    "          np.concatenate((Kappa11, Kappa12), axis=1),\n",
    "          np.concatenate((Kappa21, Kappa22), axis=1),\n",
    "          ), axis=0)\n",
    "    \n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5431e9-8f4a-47a2-93c7-26f2f996da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_log_like(r, K):\n",
    "    \"\"\"\n",
    "    Pulled from Dan's notebook, updated with Cholesky decomposition\n",
    "    https://github.com/dfm/gp/blob/main/solutions.ipynb\n",
    "    \n",
    "    The multivariate Gaussian ln-likelihood (up to a constant) for the\n",
    "    vector ``r`` given a covariance matrix ``K``.\n",
    "    \n",
    "    :param r: ``(N,)``   The residual vector with ``N`` points.\n",
    "    :param K: ``(N, N)`` The square (``N x N``) covariance matrix.\n",
    "    \n",
    "    :returns lnlike: ``float`` The Gaussian ln-likelihood. \n",
    "    \"\"\"\n",
    "    # Slow version, factor ~2x slower.\n",
    "    #return -0.5 * (np.dot(r, np.linalg.solve(K, r)) + np.linalg.slogdet(K)[1])\n",
    "\n",
    "    # Cholesky decomposition, faster\n",
    "    # For more info, check out: https://math.stackexchange.com/questions/3158303/using-cholesky-decomposition-to-compute-covariance-matrix-determinant\n",
    "    try:\n",
    "        cho_decomp = scipy.linalg.cho_factor(K)\n",
    "        log_det_cov = 2*np.sum(np.log(np.diag(cho_decomp[0])))\n",
    "        return -0.5 * (np.dot(r, scipy.linalg.cho_solve(cho_decomp, r)) + log_det_cov) #+ (len(r)*np.log(2.*np.pi)))\n",
    "    except np.linalg.LinAlgError:\n",
    "        return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99afc0a-68e5-44e4-b06b-d051a8250cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_neg_log_prob(params, t_f, t_rv, y, y_err):\n",
    "    \n",
    "    jitter = np.exp(params[0])\n",
    "    kernel_params = params[1:]\n",
    "    \n",
    "    # Compute the covariance matrix for the first GP\n",
    "    K1 = cov_mat(kernel_params[:5], t_f, t_rv)\n",
    "    \n",
    "    # Compute the covariance matrix for the second GP\n",
    "    K2 = cov_mat(kernel_params[5:], t_f, t_rv)\n",
    "    \n",
    "    K = K1 + K2\n",
    "    K[np.diag_indices_from(K)] += y_err**2 + jitter\n",
    "    \n",
    "    # Compute the negative log likelihood\n",
    "    return -gp_log_like(y, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aff330e-bc63-405b-ab4b-63e98882b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_gp_kernel(y):\n",
    "    \n",
    "    p0 = np.array([np.log(0.9**2.),\n",
    "                   0.5, -0.4, 0.7, 5.0, np.log(2.3),\n",
    "                   0.5, -0.4, 0.7, 5.0, np.log(2.3)])\n",
    "    \n",
    "    result = scipy.optimize.minimize(gp_neg_log_prob, p0, args=(t_flux, t_rad, y, np.concatenate((flux_err, rv_err))))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0b83ce-f178-428c-b8c7-c42cc91e8c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -2550.555868658847\n",
      " hess_inv: array([[ 8.39047356e-04, -4.51509981e-04, -3.52392745e-04,\n",
      "         1.74827316e-01, -8.44608990e-02,  8.48668381e-04,\n",
      "         1.20042024e-03, -9.97255202e-04, -8.19239210e-02,\n",
      "         2.84912577e-01,  1.29100678e-04],\n",
      "       [-4.51509981e-04,  5.09147942e-04,  1.76920487e-04,\n",
      "        -1.49355819e-01,  1.92784997e-03, -2.39967242e-04,\n",
      "        -5.81882689e-04,  7.07855452e-04,  1.49310855e-01,\n",
      "        -1.28011131e-01, -1.12932771e-04],\n",
      "       [-3.52392745e-04,  1.76920487e-04,  1.10911427e-03,\n",
      "        -9.23990053e-02,  9.04553566e-02, -7.45053104e-04,\n",
      "        -1.09922761e-03,  3.98978841e-05, -4.52113462e-02,\n",
      "        -2.04478738e-01, -6.04461274e-04],\n",
      "       [ 1.74827316e-01, -1.49355819e-01, -9.23990053e-02,\n",
      "         5.79368674e+01, -1.60343639e+00,  1.34959268e-01,\n",
      "         2.16649869e-01, -2.02394565e-01, -3.75555999e+01,\n",
      "         4.60416090e+01,  5.52296711e-02],\n",
      "       [-8.44608990e-02,  1.92784997e-03,  9.04553566e-02,\n",
      "        -1.60343639e+00,  2.77418329e+01, -1.47731070e-01,\n",
      "        -2.00478722e-01,  6.98173219e-02, -1.57294854e+01,\n",
      "        -4.74231916e+01, -1.79676960e-02],\n",
      "       [ 8.48668381e-04, -2.39967242e-04, -7.45053104e-04,\n",
      "         1.34959268e-01, -1.47731070e-01,  1.35862894e-03,\n",
      "         1.71399210e-03, -7.53067608e-04,  3.02586385e-02,\n",
      "         3.59990354e-01,  7.40203284e-05],\n",
      "       [ 1.20042024e-03, -5.81882689e-04, -1.09922761e-03,\n",
      "         2.16649869e-01, -2.00478722e-01,  1.71399210e-03,\n",
      "         2.48421583e-03, -1.28421657e-03, -4.10452600e-02,\n",
      "         5.13067138e-01,  2.00860484e-04],\n",
      "       [-9.97255202e-04,  7.07855452e-04,  3.98978841e-05,\n",
      "        -2.02394565e-01,  6.98173219e-02, -7.53067608e-04,\n",
      "        -1.28421657e-03,  1.64083563e-03,  2.01374878e-01,\n",
      "        -3.11675701e-01,  4.01426474e-06],\n",
      "       [-8.19239210e-02,  1.49310855e-01, -4.52113462e-02,\n",
      "        -3.75555999e+01, -1.57294854e+01,  3.02586385e-02,\n",
      "        -4.10452600e-02,  2.01374878e-01,  5.86159148e+01,\n",
      "        -9.80541840e+00,  6.56328444e-03],\n",
      "       [ 2.84912577e-01, -1.28011131e-01, -2.04478738e-01,\n",
      "         4.60416090e+01, -4.74231916e+01,  3.59990354e-01,\n",
      "         5.13067138e-01, -3.11675701e-01, -9.80541840e+00,\n",
      "         1.19816136e+02,  5.41827800e-02],\n",
      "       [ 1.29100678e-04, -1.12932771e-04, -6.04461274e-04,\n",
      "         5.52296711e-02, -1.79676960e-02,  7.40203284e-05,\n",
      "         2.00860484e-04,  4.01426474e-06,  6.56328444e-03,\n",
      "         5.41827800e-02,  7.30747431e-04]])\n",
      "      jac: array([-0.02935791, -0.00125122,  0.0335083 , -0.00018311,  0.00112915,\n",
      "        0.01815796,  0.02731323, -0.01339722,  0.00045776,  0.00082397,\n",
      "        0.02600098])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 2388\n",
      "      nit: 130\n",
      "     njev: 198\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([-1.15671512e+01,  3.91202192e-01, -5.48513203e-02,  4.69633753e+00,\n",
      "        6.23218789e+01,  1.22766396e+00,  2.39073533e+00,  6.94363744e-02,\n",
      "        2.85853270e+01, -8.14315604e+01,  1.00653895e+00])\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate((flux, rv))\n",
    "res = minimize_gp_kernel(y)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0815312-ece3-4bd4-8775-e36732e22eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat_test(params, t_test_f, t_test_rv, t_train_f, t_train_rv):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix for test data\n",
    "    \"\"\"\n",
    "    \n",
    "    #params = params[3:]\n",
    "    \n",
    "    Kappa11 = K_11(t_test_f, t_train_f, params)\n",
    "    Kappa12 = K_12(t_test_f, t_train_rv, params)\n",
    "    Kappa21 = K_21(t_test_rv, t_train_f, params)\n",
    "    Kappa22 = K_22(t_test_rv, t_train_rv, params)\n",
    "            \n",
    "    cov = np.concatenate((\n",
    "          np.concatenate((Kappa11, Kappa12), axis=1),\n",
    "          np.concatenate((Kappa21, Kappa22), axis=1),\n",
    "          ), axis=0)\n",
    "    \n",
    "    return cov\n",
    "\n",
    "def trained_cov(p):\n",
    "    \"\"\"\n",
    "    function to build covariance matrix from optimized model parameters computed from training set \n",
    "    \"\"\"\n",
    "    cov_train1 = cov_mat(p[1:6], t_flux, t_rad)\n",
    "    cov_train2 = cov_mat(p[6:], t_flux, t_rad)\n",
    "    cov_train = cov_train1 + cov_train2\n",
    "\n",
    "    cov_train[np.diag_indices_from(cov_train)] += np.concatenate((flux_err, rv_err))**2 + np.exp(p[0])\n",
    "    \n",
    "    return cov_train\n",
    "\n",
    "def predict(p, y, n_test=1000):\n",
    "    \n",
    "    cov_train = trained_cov(p)\n",
    "    \n",
    "    factor = (scipy.linalg.cholesky(cov_train, overwrite_a=True, lower=False), False)\n",
    "    alpha  = scipy.linalg.cho_solve(factor, y, overwrite_b=True)\n",
    "    \n",
    "    t_test_flux = np.linspace(min(t_flux), max(t_flux), n_test)\n",
    "    t_test_rv  = np.linspace(min(t_rad_full), max(t_rad_full), n_test)\n",
    "    \n",
    "    cov_test_only1 = cov_mat(p[1:6], t_test_flux, t_test_rv)\n",
    "    cov_test_only2 = cov_mat(p[6:],  t_test_flux, t_test_rv)\n",
    "    cov_test_only = cov_test_only1 + cov_test_only2\n",
    "    \n",
    "    cov_test1 = cov_mat_test(p[1:6], t_test_flux, t_test_rv, t_flux, t_rad) # t_flux and t_rad are training data\n",
    "    cov_test2 = cov_mat_test(p[6:],  t_test_flux, t_test_rv, t_flux, t_rad)\n",
    "    cov_test = cov_test1 + cov_test2\n",
    "    \n",
    "    mu = np.dot(cov_test, alpha)\n",
    "    var = cov_test_only[np.diag_indices_from(cov_test_only)]\n",
    "    inv_cov_test = np.linalg.solve(cov_train, cov_test.T)\n",
    "    var -= np.sum(cov_test.T * inv_cov_test, axis = 0)\n",
    "    \n",
    "    return mu, var, t_test_flux, t_test_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f43a0ca-5c8e-4718-8378-1861c73824b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, var, t_test_flux, t_test_rv = predict(res.x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc56ff0c-047a-4408-acb1-706e87893875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c92409c865d4373a57840e909fb8c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/slx5z51s7j9d_w8l_mb2blvc0001sl/T/ipykernel_21898/3504204243.py:44: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "def plot_data_and_model(p0=None):\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=2, figsize=(12, 6), gridspec_kw={'hspace':0.4})\n",
    "    \n",
    "    ax[0].scatter(t_flux, flux, color='black', s=5.0, label='LC w/ errors')#, alpha=0.5)\n",
    "    ax[0].plot(t_flux, flux-flux_err, color='grey', label='True LC', zorder=9)#, alpha=0.5)\n",
    "    \n",
    "    rv_train = ax[1].scatter(t_rad, rv, color='orange', s=100.0, alpha=0.9, zorder=10, marker='*', label='Trained RVs')\n",
    "    rv_data = ax[1].scatter(t_rad_full, rv_full, color='black', s=5.0, label='RVs w/ errors')#, alpha=0.3)\n",
    "    true_rv, = ax[1].plot(t_rad_full, rv_full-rv_err_full, color='grey', label='True RVs')#, alpha=0.3)\n",
    "    \n",
    "    ax[0].plot(t_test_flux, mu[:len(t_test_flux)], lw=2.0, color='C0', ls='-', label='GP$_\\mathrm{LC}$', zorder=10)\n",
    "    rv_gp, = ax[1].plot(t_test_rv, mu[len(t_test_flux):], lw=2.0, color='C0', ls='-', zorder=1, label='GP$_\\mathrm{RV}$')\n",
    "    \n",
    "    ax[0].fill_between(t_test_flux, y1=mu[:len(t_test_flux)]-np.sqrt(var[:len(t_test_flux)]),\n",
    "                       y2=mu[:len(t_test_flux)]+np.sqrt(var[:len(t_test_flux)]), color='C0', alpha=0.5)\n",
    "    \n",
    "    ax[1].fill_between(t_test_rv, y1=mu[len(t_test_flux):]-np.sqrt(var[len(t_test_flux):]),\n",
    "                       y2=mu[len(t_test_flux):]+np.sqrt(var[len(t_test_flux):]), color='C0', alpha=0.25)\n",
    "    \n",
    "    ax[0].set_ylabel(r\"Norm. Flux (ppt)\")\n",
    "    ax[1].set_ylabel(r\"RV (m s$^{-1}$)\")\n",
    "    \n",
    "    ax[0].set_xlabel(r\"Time (day)\")\n",
    "    ax[1].set_xlabel(r\"Time (day)\")\n",
    "    \n",
    "    ax[0].set_xlim([min(t_flux), max(t_flux)])\n",
    "    ax[1].set_xlim([min(t_rad), max(t_rad)])\n",
    "    \n",
    "    ax[0].set_ylim([min(flux)-2.0, max(flux)+2.5])\n",
    "    ax[1].set_ylim([min(rv_full)-175., max(rv_full)+150.])\n",
    "    \n",
    "    ax[0].legend(fontsize=12, markerscale=2.0)\n",
    "    rv_l1 = ax[1].legend([rv_train, rv_data], [\"Trained RVs\", \"RVs w/ errors\"], fontsize=12, markerscale=1.5, loc='lower right')\n",
    "    rv_l2 = ax[1].legend([rv_gp, true_rv], [\"GP$_\\mathrm{RV}$\", \"True RV\"], fontsize=12, markerscale=1.5, loc='lower left')\n",
    "    ax[1].add_artist(rv_l1)\n",
    "\n",
    "    data_dict_fn = \"Two Latent GPs Tests/SqExp/\"\n",
    "    plot_fn = data_dict_fn + 'f500-2500_rv700-1750_nrv{0}_seed{1}.png'.format(n_rv_cadence, rng_seed)\n",
    "    #plot_fn = data_dict_fn + 'f0-1000_rv2500-3500_nrv7_equal_spaced.png'\n",
    "    #plt.savefig(plot_fn, bbox_inches='tight', dpi=400)\n",
    "    #plt.savefig(\"Plots/two_latent_GP_model_comp_nRV_10.png\", bbox_inches='tight', dpi=400)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#plot_data_and_model(p0 = np.array([0.1, 0.04, 0.07, 5.0, 20.0, 2.0]))\n",
    "plot_data_and_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
